{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe20972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../../eqnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e101966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sympy as sp\n",
    "import numpy as np\n",
    "import heapq\n",
    "from copy import deepcopy\n",
    "from scipy.spatial.distance import cdist\n",
    "from IPython.display import display, Math, Markdown\n",
    "from expemb.model import ExpEmbTx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41a5909",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_emb = torch.load(\"../models/20220925-213952183214/saved_embddings.pth\", map_location = torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61bb2926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingMathematics:\n",
    "    def __init__(self, modelpath, exp_list, emb_list):\n",
    "        self.tokenizer = torch.load(modelpath)[\"tokenizer\"]\n",
    "        self.model = ExpEmbTx.load_from_checkpoint(modelpath, tokenizer = self.tokenizer)\n",
    "        self.emb_list = np.array(deepcopy(emb_list))\n",
    "        self.exp_list = deepcopy(exp_list)\n",
    "        print(f\"emb_list: {self.emb_list.shape}\")\n",
    "        \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def find_embedding(self, prefix_eq):\n",
    "        tensor = self.tokenizer.encode(prefix_eq)\n",
    "        src = tensor.unsqueeze(1)\n",
    "        src_mask, src_padding_mask = self.model.create_src_mask(src)\n",
    "        memory = self.model.encode(src = src, src_mask = src_mask, src_padding_mask = src_padding_mask)\n",
    "        embedding = memory[:, 0]\n",
    "        embedding = embedding[1:-1]\n",
    "        embedding = embedding.max(dim = 0)[0]\n",
    "        return embedding.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    def get_or_create_embedding(self, prefix_eq):\n",
    "        if prefix_eq not in self.exp_list:\n",
    "            print(f\"Embedding for {prefix_eq} not in the map. Computing...\")\n",
    "            emb = self.find_embedding(prefix_eq)\n",
    "            self.emb_list = np.append(self.emb_list, emb[None, :], axis = 0)\n",
    "            self.exp_list.append(prefix_eq)\n",
    "\n",
    "        return self.emb_list[self.exp_list.index(prefix_eq)]\n",
    "\n",
    "\n",
    "    def get_analogy(self, x1, y1, y2, expected_x2):\n",
    "        prefix_to_sympy = self.tokenizer.prefix_to_sympy\n",
    "        display(Markdown(f\"x1: ${sp.latex(prefix_to_sympy(x1))}$ <br />y1: ${sp.latex(prefix_to_sympy(y1))}$ <br />y2: ${sp.latex(prefix_to_sympy(y2))}$ <br />Expected x2: ${sp.latex(prefix_to_sympy(expected_x2))}$\"))\n",
    "        embx1 = self.get_or_create_embedding(x1)\n",
    "        emby1 = self.get_or_create_embedding(y1)\n",
    "        emby2 = self.get_or_create_embedding(y2)\n",
    "        _  = self.get_or_create_embedding(expected_x2)\n",
    "\n",
    "        embx2 = embx1 - emby1 + emby2\n",
    "        embx2 = embx2[None, :]\n",
    "\n",
    "        dist = cdist(self.emb_list, embx2, metric = \"cosine\")\n",
    "        dist = dist.squeeze(1)\n",
    "        maxidx = np.argpartition(dist, 8)[:8]\n",
    "\n",
    "        # Remove x1, y1, and y2\n",
    "        if self.exp_list.index(x1) in maxidx:\n",
    "            maxidx = np.delete(maxidx, np.where(maxidx == self.exp_list.index(x1)))\n",
    "        if self.exp_list.index(y1) in maxidx:\n",
    "            maxidx = np.delete(maxidx, np.where(maxidx == self.exp_list.index(y1)))\n",
    "        if self.exp_list.index(y2) in maxidx:\n",
    "            maxidx = np.delete(maxidx, np.where(maxidx == self.exp_list.index(y2)))\n",
    "        maxidx = maxidx[:5]\n",
    "\n",
    "        closest = {self.exp_list[idx] : dist[idx] for idx in maxidx}\n",
    "        closest = dict(sorted(closest.items(), key=lambda item: item[1]))\n",
    "        for exp, score in closest.items():\n",
    "            print(f\"{prefix_to_sympy(exp)} : {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e55f5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_list: (2744809, 512)\n"
     ]
    }
   ],
   "source": [
    "modelpath = \"../models/20220925-213952183214/saved_models/best.ckpt\"\n",
    "emb_math = EmbeddingMathematics(modelpath, saved_emb[\"exp_list\"], saved_emb[\"emb_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31ecbdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "x1: $\\cos{\\left(x \\right)}$ <br />y1: $\\sin{\\left(x \\right)}$ <br />y2: $\\csc{\\left(x \\right)}$ <br />Expected x2: $\\sec{\\left(x \\right)}$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for csc x not in the map. Computing...\n",
      "sec(x) : 0.3076893021697509\n",
      "x*cos(x) : 0.3529464371894493\n",
      "cos(cos(x)) : 0.3548633104427319\n",
      "x + cos(x) : 0.36909497299135174\n",
      "cos(log(x)) : 0.3762256392108363\n"
     ]
    }
   ],
   "source": [
    "emb_math.get_analogy(\"cos x\", \"sin x\", \"csc x\", \"sec x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc2c1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "x1: $\\sin{\\left(x \\right)}$ <br />y1: $\\cos{\\left(x \\right)}$ <br />y2: $\\cosh{\\left(x \\right)}$ <br />Expected x2: $\\sinh{\\left(x \\right)}$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for sinh x not in the map. Computing...\n",
      "x*cosh(x) : 0.21487585518069596\n",
      "cosh(sin(x)) : 0.2185385581099304\n",
      "sin(cosh(x)) : 0.21859363000397347\n",
      "sin(sinh(x)) : 0.2474086568472712\n",
      "10*cosh(x) : 0.2536227874401996\n"
     ]
    }
   ],
   "source": [
    "emb_math.get_analogy(\"sin x\", \"cos x\", \"cosh x\", \"sinh x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2947a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "x1: $x^{2} - 1$ <br />y1: $x + 1$ <br />y2: $x + 2$ <br />Expected x2: $x^{2} - 4$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for add pow x INT+ 2 INT- 1 not in the map. Computing...\n",
      "Embedding for add x INT+ 1 not in the map. Computing...\n",
      "Embedding for add x INT+ 2 not in the map. Computing...\n",
      "Embedding for add pow x INT+ 2 INT- 4 not in the map. Computing...\n",
      "1/(x**2 + 3) : 0.16227422927981383\n",
      "2 - 5*x**2 : 0.1658932252991101\n",
      "1/(x**2 + x) : 0.16627381949072184\n",
      "2 - 4*x**2 : 0.17113628266389436\n",
      "1/(x**2 + 2) : 0.17186165858337166\n"
     ]
    }
   ],
   "source": [
    "emb_math.get_analogy(\"add pow x INT+ 2 INT- 1\", \"add x INT+ 1\", \"add x INT+ 2\", \"add pow x INT+ 2 INT- 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "428b71d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "x1: $x^{2} - 1$ <br />y1: $x + 1$ <br />y2: $2 x + 2$ <br />Expected x2: $4 x^{2} - 4$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for add mul x INT+ 2 INT+ 2 not in the map. Computing...\n",
      "Embedding for add mul INT+ 4 pow x INT+ 2 INT- 4 not in the map. Computing...\n",
      "2*x**4 + 5*x**2/2 : 0.15826225686135298\n",
      "1/(2*x**2 - 2) : 0.16072043504838307\n",
      "4*x**(5/2) + 5*x**2/2 : 0.1607452568100033\n",
      "2 - 5*x**2 : 0.16141582684218314\n",
      "(2 - x**2)**(-2) : 0.1614917403816265\n"
     ]
    }
   ],
   "source": [
    "emb_math.get_analogy(\"add pow x INT+ 2 INT- 1\", \"add x INT+ 1\", \"add mul x INT+ 2 INT+ 2\", \"add mul INT+ 4 pow x INT+ 2 INT- 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ce04ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.randn(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88965842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e00eb53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 512)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.append(a, b[None, :], axis = 0)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d2771b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
